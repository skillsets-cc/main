schema_version: "1.0"
batch_id: "1.10.001"

# Identity
name: "Valence"
version: "3.0.5"
description: "Built for agency > automation, Valence is an opinionated path to quality output."

author:
  handle: "@supercollectible"
  url: "https://github.com/supercollectible"

# Verification
verification:
  production_links:
    - url: "https://skillsets.cc"
  production_proof: "./PROOF.md"
  audit_report: "./AUDIT_REPORT.md"

# Discovery
tags:
  - "teammates"
  - "multi-agent"
  - "spec-driven"
  - "test-driven"
  - "atomic"
  - "first-principles"

compatibility:
  claude_code_version: ">=1.0.0"
  languages:
    - "any"

# Lifecycle
status: "active"

# MCP Servers (discovered in content/docker/litellm/config.yaml)
mcp_servers:
  - name: "litellm-proxy"
    type: "docker"
    image: "ghcr.io/berriai/litellm:main-latest"
    mcp_reputation: "ghcr: berriai/litellm — actively maintained LLM proxy by BerriAI, widely adopted for multi-model routing. Exposes port 4000 locally, config and project mounted read-only. Used here to provide Kimi and Deepseek access for adversarial review and pattern matching."
    researched_at: "2026-02-10"
    servers:
      - name: "context7"
        command: "npx"
        args: ["-y", "@upstash/context7-mcp"]
        mcp_reputation: "npm: @upstash/context7-mcp — 304k weekly downloads, MIT licensed, v2.1.1. Maintained by Upstash. Provides live library documentation to LLMs via resolve-library-id and query-docs tools."
        researched_at: "2026-02-10"
      - name: "filesystem"
        command: "npx"
        args: ["-y", "@modelcontextprotocol/server-filesystem", "/project:ro"]
        mcp_reputation: "npm: @modelcontextprotocol/server-filesystem — 171k weekly downloads, MIT licensed, v2026.1.14. Official MCP server by Anthropic's modelcontextprotocol org. Read-only codebase access (:ro flag)."
        researched_at: "2026-02-10"

# Content
entry_point: "./content/CLAUDE.md"
